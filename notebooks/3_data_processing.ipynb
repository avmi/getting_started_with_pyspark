{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "import holidays\n",
    "\n",
    "# pandas and plotting libraries for visualizations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# module containing functions for manipulation pyspark dataframes\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# class which will let us create spark objects\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# helper functions for the class\n",
    "from helpers import display, read_df, write_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PySpark SQL docs](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('data_processing')\n",
    "    .master('local[2]')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_df(spark, '../taxi_2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only have tip data for credit card transactions\n",
    "tips = df.where(f.col('payment_type') == 'Credit Card')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns we get for free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    tips.select(\n",
    "        'trip_id',\n",
    "        'company',\n",
    "        'trip_miles',\n",
    "        'fare',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    tips.select(\n",
    "        'start_time',\n",
    "        'end_time',\n",
    "        f.month('start_time').alias('start_month'),\n",
    "        f.dayofweek('start_time').alias('start_day_of_week'),\n",
    "        f.hour('start_time').alias('start_hour'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    tips\n",
    "    .withColumn(\n",
    "        'trip_minutes',\n",
    "        (f.unix_timestamp(f.col('end_time')) - f.unix_timestamp(f.col('start_time')))/60,\n",
    "    )\n",
    "    .select('start_time', 'end_time', 'trip_minutes')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location based feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_miles_by_census_tract = (\n",
    "    tips\n",
    "    .groupby('dropoff_census_tract')\n",
    "    .agg(f.avg(f.col('trip_miles')).alias('avg_miles_by_census_tract'))\n",
    ")\n",
    "\n",
    "display(avg_miles_by_census_tract, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    tips\n",
    "    .join(avg_miles_by_census_tract, on='dropoff_census_tract', how='left')\n",
    "    .select('pickup_census_tract', 'dropoff_census_tract', 'avg_miles_by_census_tract')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_block_window = Window().partitionBy('dropoff_census_tract')\n",
    "\n",
    "display(\n",
    "    tips\n",
    "    .withColumn('avg_miles_by_census_tract', f.avg(f.col('trip_miles')).over(census_block_window))\n",
    "    .select('pickup_census_tract', 'dropoff_census_tract', 'avg_miles_by_census_tract')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions (UDFs)\n",
    "for sometimes it's helpful to take advandate of other python libraries, and udfs let us do that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example python UDF: adding and verifying a uuid column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_uuid_udf = f.udf(lambda c: str(uuid.uuid4()), t.StringType())\n",
    "\n",
    "tips = tips.withColumn('trip_uuid', create_uuid_udf(f.col('trip_id')))\n",
    "\n",
    "display(tips.select('trip_uuid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = tips.withColumn(\n",
    "    'trip_uuid',\n",
    "    f.when(f.col('trip_uuid').startswith('a'), f.lit('zzzzzzzzzz')).otherwise(f.col('trip_uuid'))\n",
    ")\n",
    "# tips.cache() # why is this needed ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uuid(x):\n",
    "    \"\"\"Test if the string passed in is a valid UUID - if not, return None\"\"\"\n",
    "    try:\n",
    "        uuid.UUID(x)\n",
    "        return x\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "check_uuid_udf = f.udf(check_uuid)\n",
    "\n",
    "tips = (\n",
    "    tips\n",
    "    .withColumn('trip_uuid_check', check_uuid_udf(f.col('trip_uuid')))\n",
    ")\n",
    "display(\n",
    "    tips\n",
    "    .where(f.col('trip_uuid_check').isNull())\n",
    "    .select('trip_uuid', 'trip_uuid_check')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example pandas (vectorized) UDF: finding holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = USFederalHolidayCalendar()\n",
    "holiday_list = cal.holidays(start='2016-01-01', end='2017-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.pandas_udf('integer')\n",
    "def holiday_udf(x):\n",
    "    return x.isin(holiday_list)\n",
    "\n",
    "\n",
    "tips = tips.withColumn('is_holiday', holiday_udf(f.col('start_time')))\n",
    "\n",
    "display(tips.select('is_holiday', 'start_time').where('is_holiday = 1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you build a function that takes in a dataframe with the columns found in `taxi_2016` and output features discussed above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What other data points might be useful to predict what tip a given trip would have?\n",
    "### Can you construct a column with that information?\n",
    "\n",
    "Since this prompt is wide open I've not written out a direct solution, but encourage\n",
    "you to play with different options!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
