{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# pandas and plotting libraries for visualizations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# module containing functions for manipulation pyspark dataframes\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# class which will let us create spark objects\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# modeling\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# helper functions for the class\n",
    "from helpers import display, read_df, write_df, feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PySpark ML docs](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('model')\n",
    "    .master('local[2]')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(raw_df):\n",
    "    avg_miles_by_census_tract = (\n",
    "        raw_df\n",
    "        .groupby('dropoff_census_tract')\n",
    "        .agg(f.avg(f.col('trip_miles')).alias('avg_trip_miles_by_dropoff_census_tract'))\n",
    "    )\n",
    "\n",
    "    features = (\n",
    "        raw_df\n",
    "        .where(f.col('tips').isNotNull())\n",
    "        .join(avg_miles_by_census_tract, on='dropoff_census_tract')\n",
    "        .select(\n",
    "            'trip_id',\n",
    "            'company',\n",
    "            'trip_miles',\n",
    "            'fare',\n",
    "            f.month('start_time').alias('start_month'),\n",
    "            f.dayofweek('start_time').alias('start_day_of_week'),\n",
    "            f.hour('start_time').alias('start_hour'),\n",
    "            (\n",
    "                f.unix_timestamp(f.col('end_time'))\n",
    "                - f.unix_timestamp(f.col('start_time'))\n",
    "            ).alias('trip_minutes'),\n",
    "            'avg_trip_miles_by_dropoff_census_tract',\n",
    "            f.col('tips').alias('label'),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_df(spark, '../taxi_2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only have tip data for credit card transactions\n",
    "tips = df.where(f.col('payment_type') == 'Credit Card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw, test_raw = tips.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = build_features(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = build_features(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nulls in training set\n",
    "total_rows = train.count()\n",
    "display(\n",
    "    train.agg(\n",
    "        *[(total_rows - f.count(c)).alias(c) for c in train.columns]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['start_month', 'start_day_of_week', 'start_hour', 'company']\n",
    "indexed_categorical_cols = [c + '_ind' for c in categorical_cols]\n",
    "\n",
    "numeric_cols = ['trip_miles', 'fare', 'trip_minutes', 'avg_trip_miles_by_dropoff_census_tract']\n",
    "imputed_numeric_cols = [c + '_imp' for c in numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.select('trip_id', *categorical_cols, *[f.col(c).cast(t.DoubleType()) for c in numeric_cols], 'label')\n",
    "train = train.fillna('no_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.select('trip_id', *categorical_cols, *[f.col(c).cast(t.DoubleType()) for c in numeric_cols], 'label')\n",
    "test = test.fillna('no_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages(\n",
    "    [\n",
    "        *[StringIndexer(inputCol=c, outputCol=c+'_ind', handleInvalid='keep') for c in categorical_cols],\n",
    "        Imputer(inputCols=numeric_cols, outputCols=imputed_numeric_cols),\n",
    "        VectorAssembler(inputCols=imputed_numeric_cols + indexed_categorical_cols, outputCol='features'),\n",
    "        RandomForestRegressor(maxBins=60),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.cache()\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='rmse'\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE on test data = {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most important features:')\n",
    "feature_importances(predictions, model.stages[6], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = (\n",
    "    predictions\n",
    "    .select('prediction', 'label')\n",
    "    .sample(withReplacement=False, fraction=.01)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.regplot(to_plot['prediction'], to_plot['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(to_plot['prediction'] - to_plot['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
